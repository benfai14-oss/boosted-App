Boosted-App: Climate-Driven Commodity Risk & Hedging Pipeline

1. Purpose & High-Level Architecture

Boosted-App is an end-to-end analytical pipeline that integrates climate risk, agricultural supply dynamics, and commodity price modeling to generate defensible and transparent hedging recommendations.

The project is built around four modular layers:
	1.	Layer A â€” Ingestion: Retrieve and standardize market, weather, and supply data
	2.	Layer B â€” Climate Index: Build a global climate stress index (0â€“100)
	3.	Layer C â€” Market Modeling & Hedging: ARIMAX + hedging logic
	4.	Layer D â€” Dashboard Interface: Interactive Streamlit exploration

This structure ensures transparency, reproducibility, and production-grade organization.

â¸»

2. Repository Structure (Logical Overview)

ğŸ“ ingestion/

Layer A. Fetches historical weather anomalies, supply data, and commodity price time series.
Main script:
	â€¢	scripts/pull_all.py â†’ Produces standardized datasets for a selected commodity.

â¸»

ğŸ“ data/silver/

Cleaned, standardized intermediate datasets:
	â€¢	Weather anomalies
	â€¢	Market prices
	â€¢	Agricultural supply
	â€¢	Merged silver_data.csv

These are aligned and ready for climate signal processing.

â¸»

ğŸ“ climate_index/

Layer B. Builds the Global Climate Stress Index using:
	â€¢	Weather anomalies
	â€¢	Supply shifts
	â€¢	Commodity-specific region weights
Output:
data/gold/<commodity>_global_index.json

ğŸ“ data/gold/

Final analytical outputs, consumed by the dashboard:
	â€¢	Climate index
	â€¢	ARIMAX forecasts (with confidence intervals)
	â€¢	Hedging recommendation
	â€¢	Raw merged datasets

â¸»

ğŸ“ market_models/

Layer C. Implements the extended ARIMAX model:
	â€¢	Log returns
	â€¢	Lagged features
	â€¢	Climate risk factor
	â€¢	Seasonality
	â€¢	Forecast intervals

Output:
data/gold/<commodity>_forecast.json


â¸»

ğŸ“ hedging/

Layer C. Business-oriented hedging logic.
hedging/advanced.py computes:
	â€¢	Hedge ratio
	â€¢	Hedge notional
	â€¢	Instrument (future/option)
	â€¢	Recommended maturity (last Thursday â‰¤ last forecast date)
	â€¢	Indicative strike
	â€¢	Justification text

Output:
data/gold/<commodity>_hedge_rec.json


â¸»

ğŸ“ interface/

Layer D. The unified CLI (interface/cli.py) and Streamlit dashboard.
CLI supports:
	â€¢	Full pipeline run
	â€¢	Independent execution of each layer
	â€¢	Launching the Streamlit dashboard

â¸»

ğŸ“ interface/streamlit_app.py

Interactive final dashboard including:
	â€¢	Hedging recommendations
	â€¢	Price forecasts + uncertainty bands
	â€¢	Climate risk evolution
	â€¢	Historical prices
	â€¢	Raw data exploration

â¸»

ğŸ“ visualization/

Plot helpers and legacy PDF generator (now replaced by Streamlit).

â¸»

ğŸ“ configs/

Commodity-level metadata and region mappings.

â¸»

ğŸ“ utils/

Logging helpers, documentation generators, safe file operations.

â¸»

ğŸ“ scripts/

Developer utilities and test harnesses (test_layer_c.py, etc.).

â¸»

3. Installation & Setup

Follow these steps to install dependencies and run the pipeline.

â¸»

3.1 Create & Activate a Virtual Environment

Using Python venv:
python3 -m venv .venv
source .venv/bin/activate

Using Conda:
conda create -n boosted python=3.10 -y
conda activate boosted


â¸»


3.2 Install Python Dependencies

Ensure you are in the repository root, then run:
pip install -r requirements.txt

If Streamlit is missing due to environment issues:
pip install streamlit

4. Running the Pipeline

4.1 Run the Entire Pipeline (Full End-to-End)

This executes:
	1.	Ingestion
	2.	Climate index computation
	3.	ARIMAX forecasting
	4.	Hedging recommendation
	5.	Streamlit dashboard

Run:
python -m interface.cli full-run \
  --commodity wheat \
  --profile balanced \
  --role importer \
  --exposure 10000

  A Streamlit dashboard will automatically launch.

â¸»

5. Running Each Step Separately

5.1 Layer A â€” Ingestion

Creates the full 15-year rolling dataset:
python -m interface.cli ingest \
  --commodity wheat \
  --regions europe \
  --start 2023-01-01 \
  --end 2024-01-01


â¸»

5.2 Layer B â€” Climate Index

Builds the climate stress indicator:
python -m interface.cli climate-index \
  --commodity wheat

â¸»

5.3 Layer C â€” Market Model Forecast

Runs the ARIMAX model:
python -m interface.cli market-model \
  --commodity wheat

â¸»

5.4 Layer C â€” Hedging Recommendation

Creates the hedging strategy:
python -m interface.cli hedge \
  --commodity wheat \
  --profile balanced \
  --role importer \
  --exposure 10000

â¸»

5.5 Layer D â€” Streamlit Dashboard Only

Open the visualization interface without running the pipeline:
python -m interface.cli report \
  --commodity wheat

â¸»

6. End-to-End Workflow Summary

The full system operates as follows:
	1.	Data ingestion: download & merge external sources
	2.	Climate index: compute a global climate-driven risk metric
	3.	Price modeling: ARIMAX with seasonality + climate â†’ forecast
	4.	Hedging logic: instrument, notional, maturity, strike, rationale
	5.	Visualization: a clean, interactive dashboard for users

This makes the project suitable for:
	â€¢	Corporates needing climate-aware hedging
	â€¢	Analysts exploring market + climate interactions
	â€¢	Developers integrating modular components
	â€¢	Academia researching climate risk in commodities

â¸»

7. Future Extensions

Potential enhancements include:
	â€¢	Multi-maturity hedging ladder
	â€¢	ML-based forecast benchmarks
	â€¢	Scenario-based climate shocks
	â€¢	Value-at-Risk climate-adjusted simulations
	â€¢	Multi-commodity cross-analysis

â¸»

8. Disclosure on the Use of Generative AI

This project was developed by our team, who designed the full system architecture, the analytical methods, the choice of models, and the structure of the user interface. All conceptual decisionsâ€”including the pipeline design (Ingestion â†’ Climate Index â†’ ARIMAX Modeling â†’ Hedging â†’ Streamlit UI), the data workflow, the mathematical modeling choices, and the hedging logicâ€”were defined and validated by us.

Generative AI was used in a supporting role, not a creative or decision-making one. Its involvement was strictly limited to:

1 - Code drafting assistance

We used an AI coding assistant to help accelerate routine development operations such as writing boilerplate, structuring functions, converting pseudocode into full Python, or generating repetitive code segments.
All core logicâ€”data ingestion rules, climate index methodology, ARIMAX extensions, and hedging strategy formulationâ€”was conceived, specified, and reviewed by the team.

2 - Code quality audits

The AI was used as an automated reviewer to:
	â€¢	identify potential bugs or inconsistencies,
	â€¢	check for edge cases or missing error handling,
	â€¢	detect unused code, inefficiencies, or structural weaknesses,
	â€¢	help enforce coherent and readable coding style across modules.

3 - Code refactoring, organization, and clean-up

The assistant facilitated:
	â€¢	reorganizing files into a cleaner architecture,
	â€¢	standardizing naming conventions and documentation,
	â€¢	removing redundant logic,
	â€¢	improving readability and maintainability.

What AI did not do
	â€¢	It did not decide the modeling approach.
	â€¢	It did not choose algorithms, parameters, or statistical techniques.
	â€¢	It did not define the business logic behind hedging.
	â€¢	It did not design the dashboard, nor the pipeline structure.
	â€¢	It did not autonomously write any part of the solution without human supervision and rewriting.

Summary

AI was a productivity and reliability tool, comparable to a smart code editor or automated reviewer, operating strictly under the teamâ€™s direction.
The intellectual design of the projectâ€”including concepts, structure, modeling rationale, risk methodology, and business logicâ€”belongs entirely to us.

